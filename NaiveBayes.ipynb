{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326d876d-e2e7-4171-bc79-626f14e89776",
   "metadata": {},
   "source": [
    "## Defining Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43571e",
   "metadata": {},
   "source": [
    "##### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df0b680-721f-4dbb-b53a-f76aa2ac9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8d4068-91c3-43a2-825d-1c2ae4be5628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define logic for Naive Bayes Classifier\n",
    "class NaiveBayesClassifier():\n",
    "\n",
    "    def Prior_Probability(self, features, target):\n",
    "        #Calculate the prior probability\n",
    "        #get the count of respective class and apply a function to count.\n",
    "        self.prior_prob = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy() \n",
    "        return self.prior_prob\n",
    "    \n",
    "    def statistics(self, features, target):\n",
    "        # Calculating mean and variance of each column and parse the data to an array. \n",
    "        \n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()           #Calculate mean of the class\n",
    "        self.variance = features.groupby(target).apply(np.var).to_numpy()        #Calculate variance of the class\n",
    "    \n",
    "        return self.mean, self.variance\n",
    "    \n",
    "    def Probability(self, label, x):     \n",
    "        \n",
    "        # calculating probability from gaussian density function assuming probability of specific target value of given specific class is normally distributed \n",
    "        mean = self.mean[label]\n",
    "        variance = self.variance[label]\n",
    "        probability = (np.exp((-1/2)*((x-mean)**2) / (2 * variance)))/(np.sqrt(2 * np.pi * variance))\n",
    "        return probability\n",
    "    \n",
    "    def Posterior_Probability(self, x):\n",
    "        # calculate the posterior probability \n",
    "        posteriors = []\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior_prob[i])                             \n",
    "            conditional = np.sum(np.log(self.Probability(i, x)))     \n",
    "            posteriors.append( prior + conditional)\n",
    "        return self.classes[np.argmax(posteriors)]                   # return class with highest posterior probability\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.rows = features.shape[0]\n",
    "        self.statistics(features, target)\n",
    "        self.Prior_Probability(features, target)\n",
    "        \n",
    "    def predict(self, test_data):\n",
    "        predictions = [self.Posterior_Probability(f) for f in test_data.to_numpy()]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e55279-030f-4ebc-82a2-015c647bd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataPreprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb842ff3",
   "metadata": {},
   "source": [
    "#### train and test model based on above algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cbf2bd-cab0-438a-a256-beb24335758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = NaiveBayesClassifier()\n",
    "nb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83ba63e-c3f7-4b9c-b837-99c5d0f2d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d41f17-7326-4bdc-ab4c-8adf9df667ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16433eb4-c9aa-4ad1-ba49-a575a055fc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7764587212911235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(nb_predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e4fa9-4d2b-459d-accd-767d44aa26bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
